{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-30T15:39:35.186996Z","iopub.execute_input":"2021-06-30T15:39:35.187399Z","iopub.status.idle":"2021-06-30T15:39:36.129303Z","shell.execute_reply.started":"2021-06-30T15:39:35.187308Z","shell.execute_reply":"2021-06-30T15:39:36.128408Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/tabular-playground-series-jun-2021/sample_submission.csv\n/kaggle/input/tabular-playground-series-jun-2021/train.csv\n/kaggle/input/tabular-playground-series-jun-2021/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2021/test.csv')\nids_train = train.id\nids_test = test.id\ntrain = train.drop(columns = 'id')\ntest = test.drop(columns = 'id')\ntest = np.array(test)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T15:39:37.676195Z","iopub.execute_input":"2021-06-30T15:39:37.676620Z","iopub.status.idle":"2021-06-30T15:39:39.695548Z","shell.execute_reply.started":"2021-06-30T15:39:37.676573Z","shell.execute_reply":"2021-06-30T15:39:39.694537Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train.target = train.target.apply(lambda x:int(x[-1:])-1)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T15:39:41.196020Z","iopub.execute_input":"2021-06-30T15:39:41.196362Z","iopub.status.idle":"2021-06-30T15:39:41.371624Z","shell.execute_reply.started":"2021-06-30T15:39:41.196334Z","shell.execute_reply":"2021-06-30T15:39:41.370868Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_label=train.target\ntrain= train.drop(columns = 'target')","metadata":{"execution":{"iopub.status.busy":"2021-06-30T15:39:42.016112Z","iopub.execute_input":"2021-06-30T15:39:42.016504Z","iopub.status.idle":"2021-06-30T15:39:42.160018Z","shell.execute_reply.started":"2021-06-30T15:39:42.016475Z","shell.execute_reply":"2021-06-30T15:39:42.159089Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_x,test_x,train_labels,test_labels = train_test_split(train,train_label,test_size=0.2,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T15:39:42.866300Z","iopub.execute_input":"2021-06-30T15:39:42.866789Z","iopub.status.idle":"2021-06-30T15:39:43.022152Z","shell.execute_reply.started":"2021-06-30T15:39:42.866750Z","shell.execute_reply":"2021-06-30T15:39:43.021235Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_x = np.array(train_x)\ntest_x = np.array(test_x)\ntrain_labels = np.array(train_labels)\ntest_labels = np.array(test_labels)\ntrain_x = torch.from_numpy(train_x).float()\ntrain_labels = torch.from_numpy(train_labels)\ntest_x = torch.from_numpy(test_x).float()\ntest_labels = torch.from_numpy(test_labels)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T15:40:56.226089Z","iopub.execute_input":"2021-06-30T15:40:56.226437Z","iopub.status.idle":"2021-06-30T15:40:56.317016Z","shell.execute_reply.started":"2021-06-30T15:40:56.226408Z","shell.execute_reply":"2021-06-30T15:40:56.316132Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nimport torch.nn.functional as F\nfrom torchvision import transforms","metadata":{"execution":{"iopub.status.busy":"2021-06-30T15:40:53.871572Z","iopub.execute_input":"2021-06-30T15:40:53.871915Z","iopub.status.idle":"2021-06-30T15:40:53.877033Z","shell.execute_reply.started":"2021-06-30T15:40:53.871887Z","shell.execute_reply":"2021-06-30T15:40:53.876059Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"\nclass MyDataset(torch.utils.data.Dataset):\n    def __init__(self, x, y):\n        super(MyDataset, self).__init__()\n        self.x = x\n        self.y = y\n\n\n    def __len__(self):\n        return self.y.shape[0]\n\n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n    \n\ntrain_set = MyDataset(train_x,train_labels)\ntrain_loader = torch.utils.data.DataLoader(train_set,batch_size=64,shuffle=True)\ntest_set = MyDataset(test_x,test_labels)\ntest_loader = torch.utils.data.DataLoader(test_set,batch_size=64,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T15:41:00.625979Z","iopub.execute_input":"2021-06-30T15:41:00.626351Z","iopub.status.idle":"2021-06-30T15:41:00.634105Z","shell.execute_reply.started":"2021-06-30T15:41:00.626320Z","shell.execute_reply":"2021-06-30T15:41:00.633326Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Mynet(nn.Module):\n    def __init__(self):\n        super(Mynet,self).__init__()\n        self.network= nn.Sequential(\n            nn.Linear(75,512),\n            nn.Sigmoid(),\n            nn.Linear(512,256),\n            nn.ReLU(),\n            #nn.Dropout(p=0.5),\n            nn.Linear(256,128),\n            nn.Sigmoid(),\n            #nn.Dropout(p=0.5),\n            nn.Linear(128,32),\n            nn.ReLU(),\n            nn.Linear(32,9))\n    def forward(self,x):\n        return self.network(x)\n    \nmodel = Mynet()\noptimizer = optim.Adam(model.parameters(),lr = 0.0005)\nloss_fn = nn.CrossEntropyLoss()\n        ","metadata":{"execution":{"iopub.status.busy":"2021-06-30T15:44:30.597492Z","iopub.execute_input":"2021-06-30T15:44:30.597883Z","iopub.status.idle":"2021-06-30T15:44:30.608889Z","shell.execute_reply.started":"2021-06-30T15:44:30.597852Z","shell.execute_reply":"2021-06-30T15:44:30.607856Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"epoch = 5\nfor i in range(epoch):\n    batch=0\n    loss1=0\n    for x,y in train_loader:\n        batch+=1\n        if torch.cuda.is_available():\n            x,y = x.cuda(),y.cuda()\n    \n        optimizer.zero_grad()\n        output = model(x)\n        loss = loss_fn(output,y)\n        loss.backward()\n        optimizer.step()\n        loss1 += loss.item()\n    loss1/=batch\n    print(f\"avg loss in {i+1} epoch is {loss1}\")\n\n\n    batch1=0\n    loss2=0\n    correct =0\n    with torch.no_grad():\n        for x,y in test_loader:\n          if torch.cuda.is_available():\n            x,y = x.cuda(),y.cuda()\n          batch1+=1\n          pred = model(x)\n          loss = loss_fn(output,y)\n          loss2+=loss.item()\n          correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n        loss2/=batch\n        correct/=len(test_loader.dataset)\n        print(f\"avg loss while training is {loss2} and accuracy is {correct*100}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-30T15:44:35.337764Z","iopub.execute_input":"2021-06-30T15:44:35.338120Z","iopub.status.idle":"2021-06-30T15:45:48.116605Z","shell.execute_reply.started":"2021-06-30T15:44:35.338091Z","shell.execute_reply":"2021-06-30T15:45:48.115580Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"avg loss in 1 epoch is 1.8024201702594758\navg loss while training is 0.5063734341144561 and accuracy is 35.175\navg loss in 2 epoch is 1.774996980047226\navg loss while training is 0.5023246809959412 and accuracy is 35.425000000000004\navg loss in 3 epoch is 1.7665010908603669\navg loss while training is 0.5097041701793671 and accuracy is 35.685\navg loss in 4 epoch is 1.759474776172638\navg loss while training is 0.5217420343399047 and accuracy is 35.66\navg loss in 5 epoch is 1.753707072353363\navg loss while training is 0.5227172166824341 and accuracy is 35.894999999999996\n","output_type":"stream"}]},{"cell_type":"code","source":"\nwith torch.no_grad():\n    test = torch.tensor(test).float()\n    if torch.cuda.is_available():\n        test = test.cuda()\n    pred = F.softmax(model(test),dim=1)\n    print(pred[0])\n\npred = np.array(pred)\nans = pd.DataFrame(pred,index=ids_test,columns=[\"Class_\"+ str(i+1) for i in range(9)])\nans.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-30T15:45:56.872901Z","iopub.execute_input":"2021-06-30T15:45:56.873306Z","iopub.status.idle":"2021-06-30T15:45:59.077072Z","shell.execute_reply.started":"2021-06-30T15:45:56.873270Z","shell.execute_reply":"2021-06-30T15:45:59.075917Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"tensor([0.0682, 0.4647, 0.1591, 0.0229, 0.0128, 0.1105, 0.0173, 0.0326, 0.1118])\n","output_type":"stream"}]},{"cell_type":"code","source":"!kaggle competitions submit -c tabular-playground-series-jun-2021 -f submission.csv -m \"Message\"","metadata":{"execution":{"iopub.status.busy":"2021-06-30T15:46:11.797433Z","iopub.execute_input":"2021-06-30T15:46:11.797807Z","iopub.status.idle":"2021-06-30T15:46:12.890775Z","shell.execute_reply.started":"2021-06-30T15:46:11.797773Z","shell.execute_reply":"2021-06-30T15:46:12.889970Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Traceback (most recent call last):\n  File \"/opt/conda/bin/kaggle\", line 5, in <module>\n    from kaggle.cli import main\n  File \"/opt/conda/lib/python3.7/site-packages/kaggle/__init__.py\", line 23, in <module>\n    api.authenticate()\n  File \"/opt/conda/lib/python3.7/site-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\n    self.config_file, self.config_dir))\nOSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}