{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-10T07:03:51.870139Z","iopub.execute_input":"2021-07-10T07:03:51.870517Z","iopub.status.idle":"2021-07-10T07:04:33.618484Z","shell.execute_reply.started":"2021-07-10T07:03:51.870483Z","shell.execute_reply":"2021-07-10T07:04:33.617364Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision import transforms\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing","metadata":{"execution":{"iopub.status.busy":"2021-07-11T13:34:27.195598Z","iopub.execute_input":"2021-07-11T13:34:27.195941Z","iopub.status.idle":"2021-07-11T13:34:30.223548Z","shell.execute_reply.started":"2021-07-11T13:34:27.195912Z","shell.execute_reply":"2021-07-11T13:34:30.222432Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom torchvision.io import read_image\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, labels, img_dir, transform=None, target_transform=None):\n        self.img_labels = labels\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])\n        image = (Image.open(img_path))\n        label = self.img_labels.iloc[idx,1]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return [image, label]","metadata":{"execution":{"iopub.status.busy":"2021-07-11T13:34:30.225551Z","iopub.execute_input":"2021-07-11T13:34:30.226003Z","iopub.status.idle":"2021-07-11T13:34:30.235443Z","shell.execute_reply.started":"2021-07-11T13:34:30.225957Z","shell.execute_reply":"2021-07-11T13:34:30.234253Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/100-bird-species/birds/birds.csv')\n'''labels_train=df.labels[0:39364]\nlabels_test = df.labels[39364:40739]\nlabels_valid = df.labels[40739:42114]'''\nnew=df.drop(['Unnamed: 0','data set'],axis=1)\nnew['filepaths']=new['filepaths'].str.replace('\\\\','/')\nlabel_encoder = preprocessing.LabelEncoder()\nnew['labels']= label_encoder.fit_transform(new['labels'])\nnew\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T13:34:30.237581Z","iopub.execute_input":"2021-07-11T13:34:30.238305Z","iopub.status.idle":"2021-07-11T13:34:30.421214Z","shell.execute_reply.started":"2021-07-11T13:34:30.238258Z","shell.execute_reply":"2021-07-11T13:34:30.418686Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n  \n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                 filepaths  labels\n0      train/AFRICAN CROWNED CRANE/001.jpg       0\n1      train/AFRICAN CROWNED CRANE/002.jpg       0\n2      train/AFRICAN CROWNED CRANE/003.jpg       0\n3      train/AFRICAN CROWNED CRANE/004.jpg       0\n4      train/AFRICAN CROWNED CRANE/005.jpg       0\n...                                    ...     ...\n42109  valid/YELLOW HEADED BLACKBIRD/1.jpg     274\n42110  valid/YELLOW HEADED BLACKBIRD/2.jpg     274\n42111  valid/YELLOW HEADED BLACKBIRD/3.jpg     274\n42112  valid/YELLOW HEADED BLACKBIRD/4.jpg     274\n42113  valid/YELLOW HEADED BLACKBIRD/5.jpg     274\n\n[42114 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepaths</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train/AFRICAN CROWNED CRANE/001.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train/AFRICAN CROWNED CRANE/002.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train/AFRICAN CROWNED CRANE/003.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train/AFRICAN CROWNED CRANE/004.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train/AFRICAN CROWNED CRANE/005.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>42109</th>\n      <td>valid/YELLOW HEADED BLACKBIRD/1.jpg</td>\n      <td>274</td>\n    </tr>\n    <tr>\n      <th>42110</th>\n      <td>valid/YELLOW HEADED BLACKBIRD/2.jpg</td>\n      <td>274</td>\n    </tr>\n    <tr>\n      <th>42111</th>\n      <td>valid/YELLOW HEADED BLACKBIRD/3.jpg</td>\n      <td>274</td>\n    </tr>\n    <tr>\n      <th>42112</th>\n      <td>valid/YELLOW HEADED BLACKBIRD/4.jpg</td>\n      <td>274</td>\n    </tr>\n    <tr>\n      <th>42113</th>\n      <td>valid/YELLOW HEADED BLACKBIRD/5.jpg</td>\n      <td>274</td>\n    </tr>\n  </tbody>\n</table>\n<p>42114 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(227),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\ntrain_data = CustomImageDataset(new[:][0:39364],'../input/100-bird-species/birds/',transform=transform)\ntest_data = CustomImageDataset(new[:][39364:40739],'../input/100-bird-species/birds/',transform=transform)\nvalid_data = CustomImageDataset(new[:][40739:442114],'../input/100-bird-species/birds/',transform=transform)\n\ntraining_dataloader = DataLoader(train_data,batch_size=64,shuffle=True)\ntesting_dataloader = DataLoader(test_data,batch_size=1375,shuffle=True)\nvalid_dataloader = DataLoader(valid_data,batch_size=64,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:41:57.733351Z","iopub.execute_input":"2021-07-11T17:41:57.733772Z","iopub.status.idle":"2021-07-11T17:41:57.742555Z","shell.execute_reply.started":"2021-07-11T17:41:57.733739Z","shell.execute_reply":"2021-07-11T17:41:57.741284Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"\n#Architecture\nclass AlexNet(nn.Module):\n  def __init__(self):\n    super(AlexNet,self).__init__()\n    self.flatten = nn.Flatten()\n    self.convolve = nn.Sequential(\n        nn.Conv2d(3,96,kernel_size=(11,11),stride=4),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=(3,3),stride=2),\n        nn.Conv2d(96,256,kernel_size=(5,5),stride=1,padding=2),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=(3,3),stride=2),\n        nn.Conv2d(256,384,kernel_size=(3,3),stride=1,padding=1),\n        nn.ReLU(),\n        nn.Conv2d(384,384,kernel_size=(3,3),stride=1,padding=1),\n        nn.ReLU(),\n        nn.Conv2d(384,256,kernel_size=(3,3),stride=1,padding=1),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=(3,3),stride=2)\n    )\n    self.classification = nn.Sequential(\n        nn.Dropout(p=0.5),\n        nn.Linear(9216,4096),\n        nn.ReLU(),\n        nn.Dropout(p=0.5),\n        nn.Linear(4096,4096),\n        nn.ReLU(),\n        nn.Linear(4096,275)\n    )\n  def forward(self,x):\n    x=self.convolve(x)\n    x=self.flatten(x)\n    return self.classification(x)\n\n\n\nmodel = AlexNet()\nif torch.cuda.is_available():\n  model.cuda()\n\noptimizer = optim.Adam(model.parameters(),lr=0.0005)\n#optimizer = optim.SGD(model.parameters(),lr=0.01,weight_decay=0.0005,momentum=0.9)\nloss_fn = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:17:19.353564Z","iopub.execute_input":"2021-07-10T10:17:19.353881Z","iopub.status.idle":"2021-07-10T10:17:19.893142Z","shell.execute_reply.started":"2021-07-10T10:17:19.353852Z","shell.execute_reply":"2021-07-10T10:17:19.892287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nepoch = 10\nfor i in range(epoch):\n  batch=0\n  loss1=0\n  for x,y in training_dataloader:\n    batch+=1\n    if torch.cuda.is_available():\n      x,y = x.cuda(),y.cuda()\n    \n    optimizer.zero_grad()\n    output = model(x)\n    loss = loss_fn(output,y)\n    loss.backward()\n    optimizer.step()\n    loss1 += loss.item()\n  loss1/=batch\n  print(f\"avg loss in {i+1} epoch is {loss1}\")\n\n\n  batch1=0\n  correct =0\n  with torch.no_grad():\n    for x,y in testing_dataloader:\n      if torch.cuda.is_available():\n        x,y = x.cuda(),y.cuda()\n      batch1+=1\n      pred = model(x)\n      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    correct/=len(testing_dataloader.dataset)\n    print(f\" accuracy is {correct*100}\")\n    \ntorch.save(model,'./data/model1.pth')","metadata":{"execution":{"iopub.status.busy":"2021-07-10T10:17:31.022607Z","iopub.execute_input":"2021-07-10T10:17:31.022923Z","iopub.status.idle":"2021-07-10T10:51:48.215199Z","shell.execute_reply.started":"2021-07-10T10:17:31.022893Z","shell.execute_reply":"2021-07-10T10:51:48.213201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model,'/kaggle/working/model.pth')","metadata":{"execution":{"iopub.status.busy":"2021-07-10T16:46:06.759922Z","iopub.execute_input":"2021-07-10T16:46:06.760484Z","iopub.status.idle":"2021-07-10T16:46:06.838389Z","shell.execute_reply.started":"2021-07-10T16:46:06.760381Z","shell.execute_reply":"2021-07-10T16:46:06.836537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Architecture\nclass CusNet(nn.Module):\n  def __init__(self):\n    super(CusNet,self).__init__()\n    self.flatten = nn.Flatten()\n    self.convolve = nn.Sequential(\n        nn.Conv2d(3,96,kernel_size=(11,11),stride=4),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=(3,3),stride=2),\n        nn.Conv2d(96,256,kernel_size=(5,5),stride=1,padding=2),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=(3,3),stride=2),\n        nn.Conv2d(256,384,kernel_size=(3,3),stride=1,padding=1),\n        nn.BatchNorm2d(384),\n        nn.ReLU(),\n        nn.Conv2d(384,384,kernel_size=(3,3),stride=1,padding=1),\n        nn.ReLU(),\n        nn.Conv2d(384,256,kernel_size=(3,3),stride=1,padding=1),\n        nn.BatchNorm2d(256),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=(3,3),stride=2)\n    )\n    self.classification = nn.Sequential(\n        #nn.Dropout(p=0.5),\n        nn.Linear(9216,4096),\n        nn.BatchNorm1d(4096),\n        nn.ReLU(),\n        #nn.Dropout(p=0.5),\n        nn.Linear(4096,4096),\n        nn.BatchNorm1d(4096),\n        nn.ReLU(),\n        nn.Linear(4096,275)\n    )\n  def forward(self,x):\n    x=self.convolve(x)\n    x=self.flatten(x)\n    return self.classification(x)\n\n\n\nmodel_1 = CusNet()\nif torch.cuda.is_available():\n  model_1.cuda()\n\n#optimizer_1 = optim.Adam(model_1.parameters(),lr=0.0015)\noptimizer_1 = optim.SGD(model_1.parameters(),lr=0.05,weight_decay=0.0,momentum=0.9)\noptimizer_2= optim.SGD(model_1.parameters(),lr=0.06,weight_decay=0,momentum=0.9)\nloss_fn_1 = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T16:57:55.211620Z","iopub.execute_input":"2021-07-11T16:57:55.212410Z","iopub.status.idle":"2021-07-11T16:57:55.981703Z","shell.execute_reply.started":"2021-07-11T16:57:55.212332Z","shell.execute_reply":"2021-07-11T16:57:55.980605Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"epoch = 10\nfor i in range(epoch):\n  batch=0\n  loss1=0\n  for x,y in training_dataloader:\n    batch+=1\n    if torch.cuda.is_available():\n      x,y = x.cuda(),y.cuda()\n    \n    optimizer_1.zero_grad()\n    output = model_1(x)\n    loss = loss_fn_1(output,y)\n    loss.backward()\n    optimizer_1.step()\n    loss1 += loss.item()\n  loss1/=batch\n  print(f\"avg loss in {i+1} epoch is {loss1}\")\n\n\n  batch1=0\n  correct =0\n  with torch.no_grad():\n    for x,y in testing_dataloader:\n      if torch.cuda.is_available():\n        x,y = x.cuda(),y.cuda()\n      batch1+=1\n      pred = model_1(x)\n      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    correct/=len(testing_dataloader.dataset)\n    print(f\" accuracy is {correct*100}\")\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-11T13:57:15.979512Z","iopub.execute_input":"2021-07-11T13:57:15.979893Z","iopub.status.idle":"2021-07-11T14:41:29.217654Z","shell.execute_reply.started":"2021-07-11T13:57:15.979861Z","shell.execute_reply":"2021-07-11T14:41:29.215515Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"avg loss in 1 epoch is 5.443296648852237\n accuracy is 14.10909090909091\navg loss in 2 epoch is 3.467479737548085\n accuracy is 41.96363636363636\navg loss in 3 epoch is 2.2764675559161547\n accuracy is 58.03636363636364\navg loss in 4 epoch is 1.697520248495139\n accuracy is 66.76363636363635\navg loss in 5 epoch is 1.1592004722976066\n accuracy is 74.54545454545455\navg loss in 6 epoch is 0.7853174329578102\n accuracy is 76.43636363636364\navg loss in 7 epoch is 0.5001942489731621\n accuracy is 76.8\navg loss in 8 epoch is 0.2753041192719882\n accuracy is 77.81818181818181\navg loss in 9 epoch is 0.22163648183409174\n accuracy is 79.63636363636364\navg loss in 10 epoch is 0.11616546748804726\n accuracy is 79.7090909090909\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model_1,'model_1.pth')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T15:21:05.642251Z","iopub.execute_input":"2021-07-11T15:21:05.642693Z","iopub.status.idle":"2021-07-11T15:21:06.628680Z","shell.execute_reply.started":"2021-07-11T15:21:05.642662Z","shell.execute_reply":"2021-07-11T15:21:06.627579Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"epoch = 10\nfor i in range(epoch):\n  batch=0\n  loss1=0\n  for x,y in training_dataloader:\n    batch+=1\n    if torch.cuda.is_available():\n      x,y = x.cuda(),y.cuda()\n    \n    optimizer_2.zero_grad()\n    output = model_1(x)\n    loss = loss_fn_1(output,y)\n    loss.backward()\n    optimizer_2.step()\n    loss1 += loss.item()\n  loss1/=batch\n  print(f\"avg loss in {i+1} epoch is {loss1}\")\n\n\n  batch1=0\n  correct =0\n  with torch.no_grad():\n    for x,y in valid_dataloader:\n      if torch.cuda.is_available():\n        x,y = x.cuda(),y.cuda()\n      batch1+=1\n      pred = model_1(x)\n      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    correct/=len(valid_dataloader.dataset)\n    print(f\" accuracy is {correct*100}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-11T16:58:14.710129Z","iopub.execute_input":"2021-07-11T16:58:14.710475Z","iopub.status.idle":"2021-07-11T17:38:25.957065Z","shell.execute_reply.started":"2021-07-11T16:58:14.710444Z","shell.execute_reply":"2021-07-11T17:38:25.956110Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"avg loss in 1 epoch is 5.688042593466771\n accuracy is 5.163636363636363\navg loss in 2 epoch is 3.9703337209565297\n accuracy is 24.29090909090909\navg loss in 3 epoch is 2.67993829486432\n accuracy is 40.58181818181818\navg loss in 4 epoch is 1.8825152491207247\n accuracy is 50.981818181818184\navg loss in 5 epoch is 1.3629125164120228\n accuracy is 56.218181818181826\navg loss in 6 epoch is 1.022450137786664\n accuracy is 58.32727272727273\navg loss in 7 epoch is 0.6467857102730444\n accuracy is 61.45454545454545\navg loss in 8 epoch is 0.4237023291311094\n accuracy is 63.63636363636363\navg loss in 9 epoch is 0.2259197709598131\n accuracy is 64.21818181818182\navg loss in 10 epoch is 0.15325041230489778\n accuracy is 68.36363636363636\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model_1,'model_2.pth')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:42:45.133664Z","iopub.execute_input":"2021-07-11T17:42:45.134179Z","iopub.status.idle":"2021-07-11T17:42:46.219309Z","shell.execute_reply.started":"2021-07-11T17:42:45.134135Z","shell.execute_reply":"2021-07-11T17:42:46.218265Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"#using sgd and lr=0.06 and weight_decay=0\ncorrect =0\nwith torch.no_grad():\n    for x,y in testing_dataloader:\n      if torch.cuda.is_available():\n        x,y = x.cuda(),y.cuda()\n      pred = model_1(x)\n      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    correct/=len(testing_dataloader.dataset)\n    print(f\" accuracy is {correct*100}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-11T17:44:40.388770Z","iopub.execute_input":"2021-07-11T17:44:40.389197Z","iopub.status.idle":"2021-07-11T17:44:47.882399Z","shell.execute_reply.started":"2021-07-11T17:44:40.389133Z","shell.execute_reply":"2021-07-11T17:44:47.881121Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":" accuracy is 82.83636363636364\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}