{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-10T07:03:51.870139Z","iopub.execute_input":"2021-07-10T07:03:51.870517Z","iopub.status.idle":"2021-07-10T07:04:33.618484Z","shell.execute_reply.started":"2021-07-10T07:03:51.870483Z","shell.execute_reply":"2021-07-10T07:04:33.617364Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision import transforms\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing","metadata":{"execution":{"iopub.status.busy":"2021-07-15T10:13:45.296697Z","iopub.execute_input":"2021-07-15T10:13:45.297087Z","iopub.status.idle":"2021-07-15T10:13:45.306797Z","shell.execute_reply.started":"2021-07-15T10:13:45.297042Z","shell.execute_reply":"2021-07-15T10:13:45.305820Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom torchvision.io import read_image\n\nclass CustomImageDataset(Dataset):\n    def __init__(self, labels, img_dir, transform=None, target_transform=None):\n        self.img_labels = labels\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx,0])\n        image = (Image.open(img_path))\n        label = self.img_labels.iloc[idx,1]\n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        return [image, label]","metadata":{"execution":{"iopub.status.busy":"2021-07-15T10:13:47.552833Z","iopub.execute_input":"2021-07-15T10:13:47.553312Z","iopub.status.idle":"2021-07-15T10:13:47.568370Z","shell.execute_reply.started":"2021-07-15T10:13:47.553266Z","shell.execute_reply":"2021-07-15T10:13:47.567159Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/100-bird-species/birds/birds.csv')\n'''labels_train=df.labels[0:39364]\nlabels_test = df.labels[39364:40739]\nlabels_valid = df.labels[40739:42114]'''\nnew=df.drop(['Unnamed: 0','data set'],axis=1)\nnew['filepaths']=new['filepaths'].str.replace('\\\\','/')\nlabel_encoder = preprocessing.LabelEncoder()\nnew['labels']= label_encoder.fit_transform(new['labels'])\nnew\n","metadata":{"execution":{"iopub.status.busy":"2021-07-15T10:13:48.977541Z","iopub.execute_input":"2021-07-15T10:13:48.977958Z","iopub.status.idle":"2021-07-15T10:13:49.137478Z","shell.execute_reply.started":"2021-07-15T10:13:48.977895Z","shell.execute_reply":"2021-07-15T10:13:49.136715Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n  \n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                 filepaths  labels\n0      train/AFRICAN CROWNED CRANE/001.jpg       0\n1      train/AFRICAN CROWNED CRANE/002.jpg       0\n2      train/AFRICAN CROWNED CRANE/003.jpg       0\n3      train/AFRICAN CROWNED CRANE/004.jpg       0\n4      train/AFRICAN CROWNED CRANE/005.jpg       0\n...                                    ...     ...\n42109  valid/YELLOW HEADED BLACKBIRD/1.jpg     274\n42110  valid/YELLOW HEADED BLACKBIRD/2.jpg     274\n42111  valid/YELLOW HEADED BLACKBIRD/3.jpg     274\n42112  valid/YELLOW HEADED BLACKBIRD/4.jpg     274\n42113  valid/YELLOW HEADED BLACKBIRD/5.jpg     274\n\n[42114 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepaths</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train/AFRICAN CROWNED CRANE/001.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train/AFRICAN CROWNED CRANE/002.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train/AFRICAN CROWNED CRANE/003.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train/AFRICAN CROWNED CRANE/004.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train/AFRICAN CROWNED CRANE/005.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>42109</th>\n      <td>valid/YELLOW HEADED BLACKBIRD/1.jpg</td>\n      <td>274</td>\n    </tr>\n    <tr>\n      <th>42110</th>\n      <td>valid/YELLOW HEADED BLACKBIRD/2.jpg</td>\n      <td>274</td>\n    </tr>\n    <tr>\n      <th>42111</th>\n      <td>valid/YELLOW HEADED BLACKBIRD/3.jpg</td>\n      <td>274</td>\n    </tr>\n    <tr>\n      <th>42112</th>\n      <td>valid/YELLOW HEADED BLACKBIRD/4.jpg</td>\n      <td>274</td>\n    </tr>\n    <tr>\n      <th>42113</th>\n      <td>valid/YELLOW HEADED BLACKBIRD/5.jpg</td>\n      <td>274</td>\n    </tr>\n  </tbody>\n</table>\n<p>42114 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\ntransform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(227),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ])\n\ntrain_data = CustomImageDataset(new[:][0:39364],'../input/100-bird-species/birds/',transform=transform)\ntest_data = CustomImageDataset(new[:][39364:40739],'../input/100-bird-species/birds/',transform=transform)\nvalid_data = CustomImageDataset(new[:][40739:442114],'../input/100-bird-species/birds/',transform=transform)\n\ntraining_dataloader = DataLoader(train_data,batch_size=64,shuffle=True)\ntesting_dataloader = DataLoader(test_data,batch_size=1375,shuffle=True)\nvalid_dataloader = DataLoader(valid_data,batch_size=64,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T10:13:50.972638Z","iopub.execute_input":"2021-07-15T10:13:50.973035Z","iopub.status.idle":"2021-07-15T10:13:50.981147Z","shell.execute_reply.started":"2021-07-15T10:13:50.972992Z","shell.execute_reply":"2021-07-15T10:13:50.979972Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Architecture\nclass CusNet(nn.Module):\n  def __init__(self):\n    super(CusNet,self).__init__()\n    self.flatten = nn.Flatten()\n    self.convolve = nn.Sequential(\n        nn.Conv2d(3,96,kernel_size=(11,11),stride=4),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=(3,3),stride=2),\n        nn.Conv2d(96,256,kernel_size=(5,5),stride=1,padding=2),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=(3,3),stride=2),\n        nn.Conv2d(256,384,kernel_size=(3,3),stride=1,padding=1),\n        nn.BatchNorm2d(384),\n        nn.ReLU(),\n        nn.Conv2d(384,384,kernel_size=(3,3),stride=1,padding=1),\n        nn.ReLU(),\n        nn.Conv2d(384,256,kernel_size=(3,3),stride=1,padding=1),\n        nn.BatchNorm2d(256),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=(3,3),stride=2)\n    )\n    self.classification = nn.Sequential(\n        #nn.Dropout(p=0.5),\n        nn.Linear(9216,4096),\n        nn.BatchNorm1d(4096),\n        nn.ReLU(),\n        #nn.Dropout(p=0.5),\n        nn.Linear(4096,4096),\n        nn.BatchNorm1d(4096),\n        nn.ReLU(),\n        nn.Linear(4096,275)\n    )\n  def forward(self,x):\n    x=self.convolve(x)\n    x=self.flatten(x)\n    return self.classification(x)\n\ndef init_weights(m):\n    if type(m) == nn.Linear:\n        torch.nn.init.xavier_uniform(m.weight)\n        m.bias.data.fill_(0.00)\n\n\nmodel = CusNet()\nif torch.cuda.is_available():\n  model.cuda()\n\nmodel.apply(init_weights)\noptimizer_1 = optim.Adam(model.parameters(),lr=0.003,weight_decay=1e-5)\noptimizer_2 = optim.SGD(model.parameters(),lr=0.05,weight_decay=0.0,momentum=0.9)\noptimizer_3= optim.Adam(model.parameters(),lr=0.005,weight_decay=1e-5)\nloss_fn_1 = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2021-07-15T12:10:59.054174Z","iopub.execute_input":"2021-07-15T12:10:59.054521Z","iopub.status.idle":"2021-07-15T12:10:59.486612Z","shell.execute_reply.started":"2021-07-15T12:10:59.054490Z","shell.execute_reply":"2021-07-15T12:10:59.485734Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:41: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n","output_type":"stream"}]},{"cell_type":"code","source":"epoch = 10\nfor i in range(epoch):\n  batch=0\n  loss1=0\n  for x,y in training_dataloader:\n    batch+=1\n    if torch.cuda.is_available():\n      x,y = x.cuda(),y.cuda()\n    \n    optimizer_1.zero_grad()\n    output = model(x)\n    loss = loss_fn_1(output,y)\n    loss.backward()\n    optimizer_1.step()\n    loss1 += loss.item()\n  loss1/=batch\n  print(f\"avg loss in {i+1} epoch is {loss1}\")\n\n\n  batch1=0\n  correct =0\n  with torch.no_grad():\n    for x,y in valid_dataloader:\n      if torch.cuda.is_available():\n        x,y = x.cuda(),y.cuda()\n      batch1+=1\n      pred = model(x)\n      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    correct/=len(valid_dataloader.dataset)\n    print(f\" accuracy is {correct*100}\")\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:07:29.232839Z","iopub.execute_input":"2021-07-15T11:07:29.233165Z","iopub.status.idle":"2021-07-15T11:41:01.961202Z","shell.execute_reply.started":"2021-07-15T11:07:29.233136Z","shell.execute_reply":"2021-07-15T11:41:01.960307Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"avg loss in 1 epoch is 5.845470808543168\n accuracy is 7.636363636363637\navg loss in 2 epoch is 3.5501636475711673\n accuracy is 31.418181818181818\navg loss in 3 epoch is 2.3496103371892656\n accuracy is 45.018181818181816\navg loss in 4 epoch is 1.6998608098788694\n accuracy is 51.92727272727272\navg loss in 5 epoch is 1.2648443902854796\n accuracy is 54.90909090909091\navg loss in 6 epoch is 0.9641565233469009\n accuracy is 59.27272727272728\navg loss in 7 epoch is 0.7333882040791697\n accuracy is 60.58181818181818\navg loss in 8 epoch is 0.5623671172259302\n accuracy is 62.32727272727273\navg loss in 9 epoch is 0.4667882358824665\n accuracy is 63.78181818181818\navg loss in 10 epoch is 0.35036234766873836\n accuracy is 63.63636363636363\n","output_type":"stream"}]},{"cell_type":"code","source":"correct =0\nwith torch.no_grad():\n    for x,y in testing_dataloader:\n      if torch.cuda.is_available():\n        x,y = x.cuda(),y.cuda()\n      pred = model(x)\n      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    correct/=len(testing_dataloader.dataset)\n    print(f\" accuracy is {correct*100}\")","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:42:46.302461Z","iopub.execute_input":"2021-07-15T11:42:46.302806Z","iopub.status.idle":"2021-07-15T11:42:52.697556Z","shell.execute_reply.started":"2021-07-15T11:42:46.302774Z","shell.execute_reply":"2021-07-15T11:42:52.696533Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":" accuracy is 79.49090909090908\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model,'model_3.pth')","metadata":{"execution":{"iopub.status.busy":"2021-07-15T11:43:14.212432Z","iopub.execute_input":"2021-07-15T11:43:14.212745Z","iopub.status.idle":"2021-07-15T11:43:14.751185Z","shell.execute_reply.started":"2021-07-15T11:43:14.212715Z","shell.execute_reply":"2021-07-15T11:43:14.750322Z"},"trusted":true},"execution_count":20,"outputs":[]}]}